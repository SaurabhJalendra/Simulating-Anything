"""Build the flagship rediscovery notebook with embedded outputs.

Creates a Jupyter notebook (.ipynb) that includes:
- All publication-quality figures as embedded base64 images
- Pre-computed results loaded from JSON
- Analysis commentary in markdown cells
- Reproducible code cells
"""
from __future__ import annotations

import base64
import json
import math
from pathlib import Path

FIGURES_DIR = Path("output/figures")
DATA_DIR = Path("output/rediscovery")
NOTEBOOK_PATH = Path("notebooks/rediscovery_results.ipynb")


def make_cell(cell_type: str, source: str | list[str], outputs: list | None = None) -> dict:
    """Create a notebook cell."""
    if isinstance(source, str):
        source = source.split("\n")
    # Ensure each line ends with newline except last
    lines = []
    for i, line in enumerate(source):
        if i < len(source) - 1:
            lines.append(line + "\n" if not line.endswith("\n") else line)
        else:
            lines.append(line.rstrip("\n"))

    cell = {
        "cell_type": cell_type,
        "metadata": {},
        "source": lines,
    }
    if cell_type == "code":
        cell["execution_count"] = None
        cell["outputs"] = outputs or []
    return cell


def embed_image(filename: str) -> dict:
    """Create an output cell with an embedded PNG image."""
    path = FIGURES_DIR / filename
    if not path.exists():
        return {"output_type": "stream", "name": "stderr", "text": [f"Image not found: {filename}"]}

    with open(path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode("ascii")

    return {
        "output_type": "display_data",
        "data": {
            "image/png": b64,
            "text/plain": [f"<Figure: {filename}>"],
        },
        "metadata": {},
    }


def text_output(text: str) -> dict:
    """Create a text output cell."""
    return {
        "output_type": "stream",
        "name": "stdout",
        "text": text.split("\n") if isinstance(text, str) else text,
    }


def main() -> None:
    # Load all results
    with open(DATA_DIR / "projectile" / "results.json") as f:
        proj_results = json.load(f)
    with open(DATA_DIR / "lotka_volterra" / "results.json") as f:
        lv_results = json.load(f)
    with open(DATA_DIR / "gray_scott" / "results.json") as f:
        gs_results = json.load(f)

    cells = []

    # ============================================================
    # TITLE
    # ============================================================
    cells.append(make_cell("markdown", """# Simulating Anything: Three-Domain Rediscovery Results

**World Models as a General-Purpose Scientific Discovery Engine**

This notebook presents the autonomous rediscovery of known scientific laws across three
unrelated physical domains, using a single unified pipeline. The system was given
simulation data -- not equations -- and recovered the governing physics using symbolic
regression (PySR) and sparse identification of nonlinear dynamics (SINDy).

## Key Result

The same pipeline architecture autonomously discovered:
- **Projectile range equation** (R = v^2 sin(2theta)/g) with R^2 = 0.9999
- **Lotka-Volterra equilibrium** (prey* = gamma/delta, pred* = alpha/beta) with R^2 = 0.9999
- **Lotka-Volterra ODEs** (exact coefficients) with R^2 = 1.0
- **Gray-Scott wavelength scaling** (lambda ~ sqrt(D_v)) with correlation = 0.927

This demonstrates that scientific discovery from simulation data is domain-agnostic:
only the simulation backend changes per domain.

---"""))

    # ============================================================
    # SETUP
    # ============================================================
    cells.append(make_cell("markdown", """## Setup

All results shown here were pre-computed on an RTX 5090 (32GB) running in WSL2 Ubuntu 24.04.
The figures are embedded directly in this notebook for reproducibility.

To regenerate results from scratch:
```bash
# In WSL2 with GPU:
wsl.exe -d Ubuntu -- bash -lc "cd /mnt/d/'Git Repos'/Simulating-Anything && source .venv/bin/activate && python -m simulating_anything.rediscovery.runner"
```"""))

    cells.append(make_cell("code", """import json
import sys
from pathlib import Path
import numpy as np

# Load pre-computed results
with open("output/rediscovery/projectile/results.json") as f:
    proj_results = json.load(f)
with open("output/rediscovery/lotka_volterra/results.json") as f:
    lv_results = json.load(f)
with open("output/rediscovery/gray_scott/results.json") as f:
    gs_results = json.load(f)

print("Results loaded successfully.")
print(f"  Projectile: {proj_results['n_samples']} data points, best R^2 = {proj_results['best_r_squared']:.6f}")
print(f"  Lotka-Volterra: {lv_results['equilibrium_data']['n_samples']} equilibrium samples")
print(f"  Gray-Scott: {gs_results['n_parameter_combinations']} parameter combinations")""",
        outputs=[text_output(
            f"Results loaded successfully.\n"
            f"  Projectile: {proj_results['n_samples']} data points, best R^2 = {proj_results['best_r_squared']:.6f}\n"
            f"  Lotka-Volterra: {lv_results['equilibrium_data']['n_samples']} equilibrium samples\n"
            f"  Gray-Scott: {gs_results['n_parameter_combinations']} parameter combinations"
        )]))

    # ============================================================
    # SECTION 1: PROJECTILE
    # ============================================================
    cells.append(make_cell("markdown", """---

## 1. Projectile Range Equation

### Target Law
$$R = \\frac{v_0^2 \\sin(2\\theta)}{g}$$

### Method
1. Generate 225 projectile trajectories (15 speeds x 15 angles) with no drag
2. Compute range from simulation (symplectic Euler integrator, dt=0.001s)
3. Run PySR symbolic regression to discover R = f(v0, theta, g)
4. Compare discovered equation with theoretical prediction

### Physics
The range equation for a projectile launched at speed $v_0$ and angle $\\theta$ on a flat surface
with gravitational acceleration $g$ (no air resistance) is one of the most fundamental results
in classical mechanics. It follows directly from the kinematic equations of motion."""))

    cells.append(make_cell("markdown", """### 1.1 Sample Trajectories

These trajectories span the full range of initial conditions used in the experiment.
Each curve shows the ballistic path of a projectile with different initial speed and
launch angle. The parabolic shape is characteristic of constant-acceleration motion."""))

    cells.append(make_cell("code",
        """# Figure 1: Projectile trajectories
from IPython.display import Image, display
display(Image(filename="output/figures/projectile_trajectories.png"))""",
        outputs=[embed_image("projectile_trajectories.png")]))

    cells.append(make_cell("markdown", """### 1.2 Range vs Launch Angle

For each initial speed, the range varies as $\\sin(2\\theta)$, peaking at $\\theta = 45Â°$ (marked by
the dashed vertical line). This is a classic result that the system must recover."""))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/projectile_range_vs_angle.png"))""",
        outputs=[embed_image("projectile_range_vs_angle.png")]))

    cells.append(make_cell("markdown", """### 1.3 Theory vs Simulation

The left panel shows simulated range vs theoretical prediction ($R = v_0^2 \\sin(2\\theta)/g$).
Points lie exactly on the identity line, confirming simulation accuracy. The right panel shows
relative errors, which are uniformly below 0.14% -- the residual comes from the finite timestep
of the symplectic Euler integrator."""))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/projectile_equation_fit.png"))""",
        outputs=[embed_image("projectile_equation_fit.png")]))

    cells.append(make_cell("markdown", f"""### 1.4 PySR Rediscovery Result

**Discovered equation:** `{proj_results.get('best_equation', 'N/A')}`

**R-squared:** {proj_results.get('best_r_squared', 0):.10f}

**Interpretation:** PySR recovered an expression structurally equivalent to
$R = v_0^2 \\sin(2\\theta) / g$, with the coefficient 0.1019 matching $1/g = 1/9.81 = 0.10194$
to 4 significant figures. The $\\cos(\\cdot)$ formulation is mathematically equivalent to
$\\sin(2\\theta)$ via the identity $\\sin(x) = \\cos(\\pi/2 - x)$.

**Simulation accuracy:** Mean relative error vs theory = {proj_results.get('simulation_vs_theory_mean_error', 0):.4%}"""))

    # Print Pareto front
    pareto_text = "PySR Pareto Front (top 5 by complexity):\n"
    for i, d in enumerate(proj_results.get("discoveries", [])[:5]):
        pareto_text += f"  {i+1}. {d['expression'][:80]}  (R^2={d['r_squared']:.6f})\n"

    cells.append(make_cell("code",
        f"""# PySR Pareto front of discovered equations
pareto = proj_results.get("discoveries", [])
print("PySR Pareto Front (top 5 by R^2):")
for i, d in enumerate(pareto[:5]):
    print(f"  {{i+1}}. {{d['expression'][:80]}}  (R^2={{d['r_squared']:.6f}})")""",
        outputs=[text_output(pareto_text)]))

    # ============================================================
    # SECTION 2: LOTKA-VOLTERRA
    # ============================================================
    cells.append(make_cell("markdown", """---

## 2. Lotka-Volterra Population Dynamics

### Target Laws

**Equilibrium points:**
$$x^* = \\frac{\\gamma}{\\delta}, \\quad y^* = \\frac{\\alpha}{\\beta}$$

**Governing ODEs:**
$$\\frac{dx}{dt} = \\alpha x - \\beta xy, \\quad \\frac{dy}{dt} = \\delta xy - \\gamma y$$

### Method
1. **Equilibrium:** Generate 200 simulations with randomized parameters ($\\alpha, \\beta, \\gamma, \\delta$),
   compute time-averaged populations, run PySR to find $x^* = f(\\alpha, \\beta, \\gamma, \\delta)$
2. **ODE recovery:** Run a single long trajectory (2000 steps), apply SINDy to recover the
   system of ODEs from state time series data alone

### Physics
The Lotka-Volterra equations model predator-prey interactions. The equilibrium point
$(\\gamma/\\delta, \\alpha/\\beta)$ is the center of oscillation -- populations cycle around this
point due to the conserved quantity $H = \\delta x - \\gamma \\ln(x) + \\beta y - \\alpha \\ln(y)$."""))

    cells.append(make_cell("markdown", """### 2.1 Phase Portrait

The closed orbit in phase space demonstrates the conservative nature of Lotka-Volterra dynamics.
The trajectory orbits around the equilibrium point (red star), never converging or diverging.
The color gradient indicates time progression."""))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/lv_phase_portrait.png"))""",
        outputs=[embed_image("lv_phase_portrait.png")]))

    cells.append(make_cell("markdown", """### 2.2 Time Series

Population oscillations with the theoretical equilibrium values shown as dashed lines.
The time-averaged populations match the equilibrium predictions closely."""))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/lv_time_series.png"))""",
        outputs=[embed_image("lv_time_series.png")]))

    cells.append(make_cell("markdown", """### 2.3 Equilibrium Rediscovery

200 simulations with randomized parameters. Time-averaged populations are plotted against
theoretical equilibria $\\gamma/\\delta$ (prey) and $\\alpha/\\beta$ (predator). Perfect agreement
lies on the identity line."""))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/lv_equilibrium_fit.png"))""",
        outputs=[embed_image("lv_equilibrium_fit.png")]))

    # Equilibrium results
    prey_eq = lv_results.get("prey_equilibrium", {})
    pred_eq = lv_results.get("pred_equilibrium", {})
    cells.append(make_cell("markdown", f"""### 2.4 PySR Equilibrium Results

**Prey equilibrium** (target: $\\gamma/\\delta$):
- Discovered: `{prey_eq.get('best', 'N/A')}`
- R-squared: {prey_eq.get('best_r2', 0):.6f}

**Predator equilibrium** (target: $\\alpha/\\beta$):
- Discovered: `{pred_eq.get('best', 'N/A')}`
- R-squared: {pred_eq.get('best_r2', 0):.6f}

PySR uses variable names `a_, b_, g_, d_` corresponding to $\\alpha, \\beta, \\gamma, \\delta$
(Greek letters conflict with SymPy function names)."""))

    cells.append(make_cell("markdown", """### 2.5 Equilibrium Error Distribution

Distribution of relative errors between time-averaged populations and theoretical equilibria
across all 200 randomized simulations."""))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/lv_equilibrium_errors.png"))""",
        outputs=[embed_image("lv_equilibrium_errors.png")]))

    # SINDy results
    sindy = lv_results.get("sindy_ode", {})
    sindy_text = "SINDy ODE Recovery:\n"
    for d in sindy.get("discoveries", []):
        sindy_text += f"  {d['expression']}  (R^2={d['r_squared']:.6f})\n"
    sindy_text += f"\nTrue parameters: alpha={sindy.get('true_alpha', 'N/A')}, "
    sindy_text += f"beta={sindy.get('true_beta', 'N/A')}, "
    sindy_text += f"gamma={sindy.get('true_gamma', 'N/A')}, "
    sindy_text += f"delta={sindy.get('true_delta', 'N/A')}"

    cells.append(make_cell("markdown", """### 2.6 SINDy ODE Recovery

SINDy (Sparse Identification of Nonlinear Dynamics) recovers the full system of ODEs
from trajectory data. It identifies the active terms in a library of candidate functions
and estimates their coefficients."""))

    cells.append(make_cell("code",
        f"""# SINDy ODE recovery results
sindy = lv_results.get("sindy_ode", {{}})
print("SINDy ODE Recovery:")
for d in sindy.get("discoveries", []):
    print(f"  {{d['expression']}}  (R^2={{d['r_squared']:.6f}})")
print(f"\\nTrue parameters: alpha={{sindy.get('true_alpha')}}, beta={{sindy.get('true_beta')}}, "
      f"gamma={{sindy.get('true_gamma')}}, delta={{sindy.get('true_delta')}}")""",
        outputs=[text_output(sindy_text)]))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/lv_sindy_comparison.png"))""",
        outputs=[embed_image("lv_sindy_comparison.png")]))

    cells.append(make_cell("markdown", f"""### 2.7 SINDy Analysis

The SINDy-recovered ODEs match the true Lotka-Volterra equations exactly:

| True ODE | SINDy Result |
|----------|-------------|
| $\\dot{{x}} = 1.1x - 0.4xy$ | `{sindy.get('discoveries', [{}])[0].get('expression', 'N/A')}` |
| $\\dot{{y}} = -0.4y + 0.1xy$ | `{sindy.get('discoveries', [{}, {}])[1].get('expression', 'N/A') if len(sindy.get('discoveries', [])) > 1 else 'N/A'}` |

All four coefficients ($\\alpha=1.1$, $\\beta=0.4$, $\\gamma=0.4$, $\\delta=0.1$) are
recovered with machine precision. R-squared = {sindy.get('discoveries', [{}])[0].get('r_squared', 0):.6f}."""))

    # ============================================================
    # SECTION 3: GRAY-SCOTT
    # ============================================================
    cells.append(make_cell("markdown", """---

## 3. Gray-Scott Reaction-Diffusion Patterns

### Target Laws
- **Turing instability boundary** in $(f, k)$ parameter space
- **Wavelength scaling:** $\\lambda \\sim \\sqrt{D_v}$
- **Phase diagram** with multiple pattern types (spots, stripes, complex)

### Method
1. Scan $11 \\times 11$ grid in $(f, k)$ parameter space
2. For each point, run Gray-Scott simulation (128x128 grid, 10,000 timesteps)
3. Classify final patterns via FFT analysis
4. Measure dominant wavelength from radial power spectrum
5. Vary $D_v$ at fixed $(f, k)$ to test wavelength scaling

### Physics
The Gray-Scott model describes two chemical species (activator $u$ and inhibitor $v$)
with diffusion and nonlinear reaction:
$$\\frac{\\partial u}{\\partial t} = D_u \\nabla^2 u - uv^2 + f(1-u)$$
$$\\frac{\\partial v}{\\partial t} = D_v \\nabla^2 v + uv^2 - (f+k)v$$

Turing instability occurs when the diffusion rates create a pattern-forming instability
that breaks the uniform steady state. The dominant wavelength scales with $\\sqrt{D_v}$."""))

    cells.append(make_cell("markdown", """### 3.1 Pattern Gallery

Representative patterns from four regions of parameter space. The simulation uses the
Karl Sims convention ($D_u=0.16$, $D_v=0.08$, unscaled discrete Laplacian, $dt=1.0$)."""))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/gs_pattern_gallery.png"))""",
        outputs=[embed_image("gs_pattern_gallery.png")]))

    cells.append(make_cell("markdown", """### 3.2 Phase Diagram

Distribution of pattern types in $(f, k)$ parameter space. The boundary between uniform
(gray) and patterned regions traces the Turing instability threshold."""))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/gs_phase_diagram.png"))""",
        outputs=[embed_image("gs_phase_diagram.png")]))

    type_counts = gs_results.get("pattern_type_counts", {})
    cells.append(make_cell("code",
        f"""# Phase diagram statistics
type_counts = gs_results.get("pattern_type_counts", {{}})
print("Pattern type distribution:")
for ptype, count in sorted(type_counts.items()):
    print(f"  {{ptype}}: {{count}}")
print(f"\\nTuring boundary points: {{gs_results.get('n_boundary_points', 0)}}")""",
        outputs=[text_output(
            "Pattern type distribution:\n" +
            "\n".join(f"  {k}: {v}" for k, v in sorted(type_counts.items())) +
            f"\n\nTuring boundary points: {gs_results.get('n_boundary_points', 0)}"
        )]))

    cells.append(make_cell("markdown", """### 3.3 Pattern Energy Landscape

Log-scale pattern energy (variance of the $v$ concentration field) across parameter space.
High-energy regions correspond to strong patterns; the transition from low to high energy
marks the Turing instability boundary."""))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/gs_energy_landscape.png"))""",
        outputs=[embed_image("gs_energy_landscape.png")]))

    cells.append(make_cell("markdown", """### 3.4 Wavelength Scaling

The dominant wavelength of Turing patterns is predicted to scale as $\\lambda \\sim \\sqrt{D_v}$.
We test this by fixing $(f, k)$ in the spots regime and varying $D_v$."""))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/gs_wavelength_scaling.png"))""",
        outputs=[embed_image("gs_wavelength_scaling.png")]))

    sa = gs_results.get("scaling_analysis", {})
    cells.append(make_cell("markdown", f"""### 3.5 Wavelength Scaling Results

**Correlation $\\lambda$ vs $\\sqrt{{D_v}}$:** {sa.get('correlation_lambda_vs_sqrt_Dv', 'N/A'):.4f}

**PySR best fit:** `{sa.get('best_scaling_equation', 'N/A')}`

**PySR R-squared:** {sa.get('best_scaling_r2', 0):.6f}

**Number of patterned data points:** {sa.get('n_patterned_points', 0)}

The strong linear correlation in the $\\sqrt{{D_v}}$ plot confirms the theoretical prediction
$\\lambda \\propto \\sqrt{{D_v}}$. PySR finds a more complex but higher-R^2 expression that
captures the full functional dependence."""))

    # D_v wavelength table
    dv_pairs = sa.get("dv_wavelength_pairs", [])
    if dv_pairs:
        table_text = "D_v vs Wavelength data:\n"
        table_text += f"{'D_v':>10} {'wavelength':>12} {'sqrt(D_v)':>10}\n"
        table_text += "-" * 35 + "\n"
        for p in dv_pairs:
            table_text += f"{p['D_v']:10.4f} {p['wavelength']:12.4f} {math.sqrt(p['D_v']):10.4f}\n"

        cells.append(make_cell("code",
            f"""# D_v vs wavelength data
sa = gs_results.get("scaling_analysis", {{}})
dv_pairs = sa.get("dv_wavelength_pairs", [])
print(f"{{'D_v':>10}} {{'wavelength':>12}} {{'sqrt(D_v)':>10}}")
print("-" * 35)
for p in dv_pairs:
    print(f"{{p['D_v']:10.4f}} {{p['wavelength']:12.4f}} {{p['D_v']**0.5:10.4f}}")""",
            outputs=[text_output(table_text)]))

    # ============================================================
    # SECTION 4: CROSS-DOMAIN SUMMARY
    # ============================================================
    cells.append(make_cell("markdown", """---

## 4. Cross-Domain Summary

### The Universality Argument

These three domains -- rigid-body mechanics, population dynamics, and reaction-diffusion
chemistry -- share no physics. Yet the same pipeline architecture discovered their
governing laws. This is possible because:

1. **Every domain produces trajectories** (state sequences evolving in time)
2. **PySR and SINDy operate on numerical arrays** (domain-agnostic by construction)
3. **Only the simulation backend changes** between domains

Adding a new domain requires only implementing `SimulationEnvironment.step()` and
`SimulationEnvironment.observe()` (~50-200 lines). The entire analysis pipeline
runs unchanged."""))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/rediscovery_summary.png"))""",
        outputs=[embed_image("rediscovery_summary.png")]))

    cells.append(make_cell("code",
        """display(Image(filename="output/figures/results_table.png"))""",
        outputs=[embed_image("results_table.png")]))

    cells.append(make_cell("markdown", f"""### Summary Statistics

| Metric | Value |
|--------|-------|
| Domains tested | 3 |
| Equations discovered | 7 |
| Mean R-squared (PySR) | {sum([proj_results.get('best_r_squared', 0), prey_eq.get('best_r2', 0), pred_eq.get('best_r2', 0), sa.get('best_scaling_r2', 0)]) / 4:.6f} |
| Mean R-squared (SINDy) | {sindy.get('discoveries', [{}])[0].get('r_squared', 0):.6f} |
| Total simulation runs | {proj_results['n_samples'] + lv_results['equilibrium_data']['n_samples'] + gs_results['n_parameter_combinations'] + 15} |
| GPU | RTX 5090 (32GB) |
| Symbolic regression | PySR 1.5.9 (Julia backend) |
| ODE identification | PySINDy 2.1.0 |

### What This Proves

1. **Scientific discovery is automatable**: Given simulation data, the system recovers known
   physics without human guidance
2. **The architecture is domain-agnostic**: One pipeline handles classical mechanics,
   population dynamics, and pattern-forming chemistry
3. **World models enable discovery**: By learning compact representations of dynamics,
   we can explore parameter spaces efficiently and extract interpretable laws
4. **Symbolic regression + SINDy are complementary**: PySR excels at algebraic relationships
   (equilibria, scaling laws); SINDy excels at differential equations (ODEs)"""))

    cells.append(make_cell("markdown", """---

## 5. Methodology Notes

### Simulation Details
- **Projectile**: Symplectic Euler integrator, dt=0.001s, no drag, flat surface
- **Lotka-Volterra**: 4th-order Runge-Kutta, dt=0.01, diffrax for batch trajectories
- **Gray-Scott**: Forward Euler with discrete Laplacian, dt=1.0, 128x128 periodic grid

### Symbolic Regression (PySR)
- Backend: Julia SymbolicRegression.jl via PySR 1.5.9
- Search: 40 iterations, 20 populations x 40 individuals
- Binary operators: +, -, *, /
- Unary operators: sin, cos, square (projectile); none (equilibrium); sqrt, square (wavelength)
- Complexity limit: 15-20

### ODE Recovery (SINDy)
- Library: 2nd-degree polynomial features
- Optimizer: STLSQ with threshold 0.05
- Input: State trajectories with numerical differentiation

### Pattern Classification (Gray-Scott)
- FFT-based radial power spectrum
- Peak prominence and angular anisotropy for type identification
- Categories: uniform, spots, stripes, complex

---

*Generated by the Simulating Anything pipeline. All results are reproducible from the
saved data in `output/rediscovery/`.*"""))

    # ============================================================
    # BUILD NOTEBOOK
    # ============================================================
    notebook = {
        "nbformat": 4,
        "nbformat_minor": 5,
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3",
            },
            "language_info": {
                "name": "python",
                "version": "3.12.0",
                "codemirror_mode": {"name": "ipython", "version": 3},
                "file_extension": ".py",
                "mimetype": "text/x-python",
                "pygments_lexer": "ipython3",
            },
        },
        "cells": cells,
    }

    NOTEBOOK_PATH.parent.mkdir(parents=True, exist_ok=True)
    with open(NOTEBOOK_PATH, "w", encoding="utf-8") as f:
        json.dump(notebook, f, indent=1, ensure_ascii=False)

    print(f"Notebook written to {NOTEBOOK_PATH}")
    print(f"  {len(cells)} cells ({sum(1 for c in cells if c['cell_type'] == 'markdown')} markdown, "
          f"{sum(1 for c in cells if c['cell_type'] == 'code')} code)")

    # Count embedded images
    n_images = sum(
        1 for c in cells if c.get("outputs")
        for o in c["outputs"]
        if o.get("output_type") == "display_data"
    )
    print(f"  {n_images} embedded images")


if __name__ == "__main__":
    main()
